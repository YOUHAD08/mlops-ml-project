# ğŸš€ MLOps ML Project

<div align="center">

![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![MLOps](https://img.shields.io/badge/MLOps-Ready-orange.svg)
![Status](https://img.shields.io/badge/status-active-success.svg)

_A production-ready machine learning baseline project demonstrating MLOps best practices with reproducible pipelines, automated artifact generation, and comprehensive Git versioning._

[Features](#-features) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Documentation](#-documentation)

</div>

---

## ğŸ“‹ Overview

This project serves as a **comprehensive MLOps baseline** for building, training, and deploying machine learning models with industry-standard practices. It provides a structured framework for reproducible ML workflows, from data preprocessing to model evaluation and artifact management.

### ğŸ¯ Key Highlights

- âœ… **Reproducible Training Pipeline** - Consistent results across environments
- âœ… **Configuration-Driven** - Easy hyperparameter tuning via YAML
- âœ… **Automated Artifact Generation** - Models, metrics, and visualizations
- âœ… **Git-Friendly Structure** - Clean separation of code and outputs
- âœ… **Extensible Architecture** - Modular design for custom datasets and models

---

## ğŸ—ï¸ Project Architecture

```
mlops-ml-project/
â”œâ”€â”€ ğŸ“ config/
â”‚   â””â”€â”€ train.yaml              # ğŸ”§ Training configuration & hyperparameters
â”‚
â”œâ”€â”€ ğŸ“ src/                     # ğŸ§  Core ML modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data.py                 # ğŸ“Š Data loading and validation
â”‚   â”œâ”€â”€ features.py             # ğŸ”„ Preprocessing pipeline
â”‚   â””â”€â”€ model.py                # ğŸ¤– Model architecture and training
â”‚
â”œâ”€â”€ ğŸ“ scripts/                 # ğŸ¬ Execution scripts
â”‚   â”œâ”€â”€ train.py                # ğŸ‹ï¸ Model training workflow
â”‚   â””â”€â”€ evaluate.py             # ğŸ“ˆ Model evaluation workflow
â”‚
â”œâ”€â”€ ğŸ“ tests/                   # âœ… Test suite
â”‚   â””â”€â”€ test_config.py          # ğŸ§ª Configuration validation tests
â”‚
â”œâ”€â”€ ğŸ“ artifacts/               # ğŸ“¦ Generated outputs (gitignored)
â”‚   â”œâ”€â”€ model.joblib            # ğŸ’¾ Serialized trained model
â”‚   â”œâ”€â”€ metrics.json            # ğŸ“Š Performance metrics
â”‚   â”œâ”€â”€ confusion_matrix.png    # ğŸ¨ Confusion matrix visualization
â”‚   â””â”€â”€ report.json             # ğŸ“„ Detailed classification report
â”‚
â”œâ”€â”€ .gitignore                  # ğŸš« Git exclusion rules
â”œâ”€â”€ README.md                   # ğŸ“– This file
â””â”€â”€ requirements.txt            # ğŸ“š Python dependencies
```

---

## âœ¨ Features

### ğŸ”„ Automated ML Pipeline

- **Data Loading**: Seamless integration with scikit-learn datasets and custom CSV files
- **Preprocessing**: Configurable feature engineering and data transformation
- **Training**: Automated model training with configurable hyperparameters
- **Evaluation**: Comprehensive model assessment with multiple metrics

### ğŸ“Š Rich Artifact Generation

- **Serialized Models**: Production-ready model files (`.joblib` format)
- **Performance Metrics**: JSON-formatted accuracy and F1 scores
- **Visualizations**: Confusion matrices for model interpretation
- **Detailed Reports**: Per-class precision, recall, and F1-score breakdowns

### ğŸ› ï¸ Developer Experience

- **Configuration Management**: YAML-based configuration for easy experimentation
- **Modular Codebase**: Clean separation of concerns for maintainability
- **Testing Infrastructure**: Built-in test suite for configuration validation
- **Documentation**: Comprehensive inline documentation and type hints

---

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- Git
- Virtual environment tool (venv, conda, etc.)

### Quick Start

1ï¸âƒ£ **Clone the repository**

```bash
git clone https://github.com/YOUHAD08/mlops-ml-project.git
cd mlops-ml-project
```

2ï¸âƒ£ **Set up virtual environment**

```bash
# Create virtual environment
python -m venv .venv

# Activate (Git Bash on Windows)
source .venv/Scripts/activate

# Activate (Linux/macOS)
# source .venv/bin/activate
```

3ï¸âƒ£ **Install dependencies**

```bash
pip install -r requirements.txt
```

4ï¸âƒ£ **Verify installation**

```bash
python -c "import sklearn, pandas, numpy; print('âœ… All dependencies installed successfully!')"
```

---

## ğŸ’» Usage

### Training a Model

Train the model using the default configuration:

```bash
python scripts/train.py
```

**ğŸ“¤ Generated Artifacts:**

| Artifact                | Description                   | Location                         |
| ----------------------- | ----------------------------- | -------------------------------- |
| ğŸ¤– **Trained Model**    | Serialized scikit-learn model | `artifacts/model.joblib`         |
| ğŸ“Š **Metrics**          | Accuracy and macro F1 score   | `artifacts/metrics.json`         |
| ğŸ¨ **Confusion Matrix** | Visual performance heatmap    | `artifacts/confusion_matrix.png` |

**Example Output:**

```json
{
  "accuracy": 0.9667,
  "f1_macro": 0.9655,
  "timestamp": "2026-01-17T10:30:00"
}
```

---

### Evaluating a Model

Generate a detailed evaluation report:

```bash
python scripts/evaluate.py
```

**ğŸ“¤ Generated Artifacts:**

| Artifact                     | Description                   | Location                |
| ---------------------------- | ----------------------------- | ----------------------- |
| ğŸ“„ **Classification Report** | Per-class performance metrics | `artifacts/report.json` |

**Example Output:**

```json
{
  "class_0": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0
  },
  "class_1": {
    "precision": 0.95,
    "recall": 0.9,
    "f1-score": 0.92
  }
}
```

---

## âš™ï¸ Configuration

Customize your ML pipeline by editing `config/train.yaml`:

```yaml
# Dataset Configuration
dataset:
  name: "iris" # Dataset to use
  test_size: 0.2 # Train/test split ratio
  random_state: 42 # Reproducibility seed

# Model Configuration
model:
  type: "RandomForestClassifier" # Model architecture
  n_estimators: 100 # Number of trees
  max_depth: 5 # Maximum tree depth
  random_state: 42 # Model seed

# Output Configuration
artifacts:
  directory: "artifacts/" # Output directory
  save_model: true # Save trained model
  save_metrics: true # Save performance metrics
  save_plots: true # Generate visualizations
```

### ğŸ”§ Supported Configurations

- **Datasets**: Iris (default), custom CSV files
- **Models**: Random Forest, Logistic Regression, SVM (extensible)
- **Metrics**: Accuracy, F1-score, Precision, Recall
- **Visualizations**: Confusion Matrix, Feature Importance (coming soon)

---

## ğŸ“¦ Artifacts Directory

All generated files are stored in `artifacts/` (excluded from Git):

```
artifacts/
â”œâ”€â”€ ğŸ¤– model.joblib              # Trained model (serialized with joblib)
â”œâ”€â”€ ğŸ“Š metrics.json              # Overall performance metrics
â”œâ”€â”€ ğŸ¨ confusion_matrix.png      # Confusion matrix heatmap
â””â”€â”€ ğŸ“„ report.json               # Detailed classification report
```

### Artifact Details

#### ğŸ¤– `model.joblib`

- **Format**: Joblib-serialized scikit-learn model
- **Usage**: Load with `joblib.load('artifacts/model.joblib')`
- **Size**: Typically 10-50 KB for baseline models

#### ğŸ“Š `metrics.json`

- **Format**: JSON with top-level metrics
- **Includes**: Accuracy, F1-macro, timestamp
- **Purpose**: Quick performance overview

#### ğŸ¨ `confusion_matrix.png`

- **Format**: PNG image (300 DPI)
- **Dimensions**: 800x600 pixels
- **Purpose**: Visual model performance analysis

#### ğŸ“„ `report.json`

- **Format**: JSON with per-class metrics
- **Includes**: Precision, Recall, F1-score for each class
- **Purpose**: Detailed performance breakdown

---

## ğŸ“Š Dataset Information

### Default: Iris Dataset

The project uses the **Iris flower dataset** as a baseline:

- **Source**: Built into scikit-learn (no download required)
- **Samples**: 150 (50 per class)
- **Features**: 4 (sepal length/width, petal length/width)
- **Classes**: 3 (Setosa, Versicolor, Virginica)
- **Type**: Multi-class classification

### ğŸ”„ Custom Datasets

To use your own dataset, modify `config/train.yaml`:

```yaml
dataset:
  name: "custom"
  path: "data/your_dataset.csv"
  target_column: "label"
  feature_columns: ["feat1", "feat2", "feat3"]
```

**Requirements:**

- CSV format with headers
- Numerical features (or encode categorical features)
- Clear target/label column

---

## ğŸ§ª Testing

Run the test suite to validate configuration and setup:

```bash
# Run all tests
python -m pytest tests/

# Run specific test file
python -m pytest tests/test_config.py -v
```

**Test Coverage:**

- âœ… Configuration file validation
- âœ… Data loading functionality
- âœ… Model initialization
- âœ… Artifact generation

---

## ğŸ› ï¸ Tech Stack

| Component           | Technology          |
| ------------------- | ------------------- |
| **Language**        | Python 3.8+         |
| **ML Framework**    | scikit-learn        |
| **Data Processing** | pandas, numpy       |
| **Visualization**   | matplotlib, seaborn |
| **Configuration**   | PyYAML              |
| **Testing**         | pytest              |
| **Serialization**   | joblib              |

---

## ğŸ—ºï¸ Roadmap

### âœ… Current Features

- [x] Reproducible training pipeline
- [x] Automated artifact generation
- [x] Configuration management
- [x] Basic model evaluation

### ğŸ”œ Upcoming Features

- [ ] Docker containerization
- [ ] CI/CD pipeline integration
- [ ] Hyperparameter tuning (GridSearch/RandomSearch)
- [ ] Model versioning with MLflow
- [ ] Feature importance visualization
- [ ] Cross-validation support
- [ ] API endpoint for model serving
- [ ] Experiment tracking dashboard

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
